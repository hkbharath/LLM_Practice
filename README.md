# LLM Practice Notebooks

This repository contains a collection of Google Colab notebooks used for practicing and experimenting with building Large Language Models (LLMs). These notebooks cover various aspects of LLM development:

* **Inference:** Using trained LLMs for text generation and other tasks.

Other aspects of LLM development that must be explored:

* **Data Preprocessing:** Cleaning, tokenization, and preparing data for training.
* **Model Architectures:** Implementing and experimenting with different LLM architectures (e.g., Transformers).
* **Training and Fine-tuning:** Training LLMs from scratch and fine-tuning pre-trained models.
* **Evaluation:** Evaluating the performance of trained LLMs using various metrics.

## Contents
* **`online_research_assistant.ipynb`:** Build an AI-powered research assistant that can autonomously search the web and summarize articles using SmolAgents.
* **`text_to_image_interactive.ipynb`:** Notebook to build an interactive text-to-image generator application.
<!-- * **`[Add more notebooks here, with a short description]`** -->

## Getting Started

1.  **Open in Colab:** Click on the notebook you want to explore. Each notebook has a "Open in Colab" button at the top that opens the notebook directly in Google Colab.
2.  **Runtime:** Ensure you select a suitable runtime in Colab (e.g., GPU runtime for faster training). Go to `Runtime` -> `Change runtime type` and select the appropriate hardware accelerator.
3.  **Dependencies:** Some notebooks may require installing specific libraries. Follow the instructions within the notebooks to install any necessary dependencies using `!pip install ...`.
4.  **Models:** Some notebooks may require access to pretrained models. You need to have huggingface account to access the pre-trained models.
5.  **Experiment:** Modify the notebooks and experiment with different parameters and techniques.

## Prerequisites

* Basic understanding of Python and machine learning concepts.
* Familiarity with Google Colab.
* Knowledge of deep learning frameworks like PyTorch or TensorFlow (depending on the notebooks).


## Acknowledgements

* [Marktechpost](https://www.marktechpost.com/category/technology/artificial-intelligence/large-language-model/)
